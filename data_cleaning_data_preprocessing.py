# -*- coding: utf-8 -*-
"""Data cleaning/ data preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D0FUosAVVTQQj_luvj_vIfdlMfBqSQlX

Import library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""bring in the dataset"""

df = pd.read_csv('Life Expectancy Data.csv')
df.head()

#tail
df.tail()

#shape
df.shape

#info
print(df.info())

df.select_dtypes(include='object').columns

df.select_dtypes(include="number").columns.tolist()

#missing data
print(df.isnull().sum())

#find the percentage
df.isnull().sum()/len(df)*100

#find duplicated
df.duplicated().sum()

#identifiying garbage value
for i in df.select_dtypes(include='object').columns:
    print(df[i].unique())
    print(df[i].value_counts())
    print('='*50)

"""EXPLORATORY DATA ANALYSIS(EDA)"""

#descriptive statistics
df.describe().T

df.describe(include='object').T

#histogram to understand the distribution
df.hist(figsize=(20,20))
plt.show()

for i in df.select_dtypes(include='number').columns:
    sns.displot(df[i])
    plt.show()

# Boxplot to identify outliers for numerical features
for col in df.select_dtypes(include='number').columns:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

# Scatter plot to understand the relationship between 'Life expectancy ' and other numerical features
for col in df.select_dtypes(include='number').columns:
    if col != 'Life expectancy ':  # Avoid plotting against itself
        plt.figure(figsize=(8, 6))
        sns.scatterplot(x=df[col], y=df['Life expectancy '])
        plt.title(f'Scatter Plot of Life Expectancy vs. {col}')
        plt.xlabel(col)
        plt.ylabel('Life Expectancy')
        plt.show()

# Calculate the correlation matrix
correlation_matrix = df.select_dtypes(include='number').corr()

# Create a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix Heatmap')
plt.show()

df.isnull().sum()

df.info()

"""MISSING VALUE THEATMENTS"""

df.head()

# prompt: choose the method of imputing missing values like mean, median , mode or KNNIputer ignore the target data

# Import SimpleImputer from sklearn
from sklearn.impute import SimpleImputer

# Create a SimpleImputer object with strategy='mean'
imputer_mean = SimpleImputer(strategy='mean')

# Create a SimpleImputer object with strategy='median'
imputer_median = SimpleImputer(strategy='median')

# Create a SimpleImputer object with strategy='most_frequent' (mode)
imputer_mode = SimpleImputer(strategy='most_frequent')


# Iterate through numerical columns and impute missing values using mean
for col in df.select_dtypes(include=np.number).columns:
    if df[col].isnull().any():
        df[col] = imputer_mean.fit_transform(df[[col]])


# Example using median imputation for a specific column (if needed):
# df['column_name'] = imputer_median.fit_transform(df[['column_name']])


# Example using mode imputation for a specific column (if needed):
# df['another_column'] = imputer_mode.fit_transform(df[['another_column']])

# Display the updated DataFrame (optional)
print(df.isnull().sum())

# prompt: choose the method of imputing missing values with KNNIputer ignore the target data

from sklearn.impute import KNNImputer

# Create a KNNImputer object
imputer = KNNImputer(n_neighbors=5) # You can adjust n_neighbors

# Apply imputation to numerical features, excluding the target variable
numerical_cols = df.select_dtypes(include=np.number).columns
numerical_cols = numerical_cols.drop('Life expectancy ') # Assuming 'Life expectancy ' is your target
df[numerical_cols] = imputer.fit_transform(df[numerical_cols])

# Display the updated DataFrame (optional)
print(df.isnull().sum())

"""OUTLINERS TREATMENTS"""

def wisker(col):
  print(col.name)
  q1, q3 = np.percentile(col, [25, 75])
  iqr = q3 - q1
  lower_bound = q1 - (1.5 * iqr)
  upper_bound = q3 + (1.5 * iqr)
  print('lower_bound: ',lower_bound)
  print('upper_bound: ',upper_bound)
  print()
  return lower_bound, upper_bound

df.head()

df.columns

for i in df.select_dtypes(include='number').columns:
  lw,uw = wisker(df[i])
  df[i] = np.where(df[i] > uw, uw, df[i])
  df[i] = np.where(df[i] < lw, lw, df[i])

"""ENCODING OF DATA"""

dumy = pd.get_dummies(data=df, columns=['Status', 'Country'], drop_first=True)
dumy.head()